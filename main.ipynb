{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial code to test audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "print(sd.query_devices())  # Find virtual cable's index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "\n",
    "# Define parameters\n",
    "duration = 5  # seconds\n",
    "sample_rate = 16000  # Hz\n",
    "\n",
    "# Record audio\n",
    "print(\"Recording...\")\n",
    "audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=2, dtype=np.float32)\n",
    "sd.wait()  # Wait until recording is finished\n",
    "print(\"Recording finished.\")\n",
    "\n",
    "# Play the recorded audio\n",
    "print(\"Playing back the recorded audio...\")\n",
    "sd.play(audio_data, samplerate=sample_rate)\n",
    "sd.wait()  # Wait until playback is finished\n",
    "print(\"Playback finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Playing back the recorded audio...\")\n",
    "sd.play(audio_data, samplerate=sample_rate)\n",
    "sd.wait()  # Wait until playback is finished\n",
    "print(\"Playback finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import queue\n",
    "from collections import deque\n",
    "from whispercpp import Whisper\n",
    "from openai import OpenAI\n",
    "import soundfile as sf\n",
    "import os\n",
    "from io import BytesIO\n",
    "import keyboard\n",
    "from groq import Groq\n",
    "import time\n",
    "import pyaudio\n",
    "import wave\n",
    "import tempfile\n",
    "import pyperclip\n",
    "import webrtcvad\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tf-keras) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.0)\n",
      "Downloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 15.6 MB/s eta 0:00:00\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.14.1-cp312-cp312-win_amd64.whl.metadata (50 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\utkar\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "   ---------------------------------------- 0.0/376.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 6.8/376.0 MB 42.0 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 11.8/376.0 MB 29.5 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 14.2/376.0 MB 24.7 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 15.7/376.0 MB 20.6 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 16.5/376.0 MB 16.3 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 16.8/376.0 MB 14.9 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 17.3/376.0 MB 12.1 MB/s eta 0:00:30\n",
      "   - -------------------------------------- 17.8/376.0 MB 11.0 MB/s eta 0:00:33\n",
      "   - -------------------------------------- 18.4/376.0 MB 10.1 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 19.1/376.0 MB 9.2 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 19.7/376.0 MB 8.6 MB/s eta 0:00:42\n",
      "   -- ------------------------------------- 20.4/376.0 MB 8.1 MB/s eta 0:00:44\n",
      "   -- ------------------------------------- 21.2/376.0 MB 7.8 MB/s eta 0:00:46\n",
      "   -- ------------------------------------- 22.3/376.0 MB 7.5 MB/s eta 0:00:48\n",
      "   -- ------------------------------------- 23.3/376.0 MB 7.3 MB/s eta 0:00:49\n",
      "   -- ------------------------------------- 24.4/376.0 MB 7.2 MB/s eta 0:00:49\n",
      "   -- ------------------------------------- 25.4/376.0 MB 7.0 MB/s eta 0:00:51\n",
      "   -- ------------------------------------- 26.5/376.0 MB 6.9 MB/s eta 0:00:51\n",
      "   -- ------------------------------------- 27.5/376.0 MB 6.8 MB/s eta 0:00:52\n",
      "   --- ------------------------------------ 29.1/376.0 MB 6.8 MB/s eta 0:00:52\n",
      "   --- ------------------------------------ 30.1/376.0 MB 6.7 MB/s eta 0:00:52\n",
      "   --- ------------------------------------ 31.5/376.0 MB 6.7 MB/s eta 0:00:52\n",
      "   --- ------------------------------------ 33.0/376.0 MB 6.7 MB/s eta 0:00:52\n",
      "   --- ------------------------------------ 34.6/376.0 MB 6.7 MB/s eta 0:00:51\n",
      "   --- ------------------------------------ 35.9/376.0 MB 6.7 MB/s eta 0:00:51\n",
      "   ---- ----------------------------------- 37.7/376.0 MB 6.8 MB/s eta 0:00:51\n",
      "   ---- ----------------------------------- 39.6/376.0 MB 6.8 MB/s eta 0:00:50\n",
      "   ---- ----------------------------------- 40.9/376.0 MB 6.8 MB/s eta 0:00:49\n",
      "   ---- ----------------------------------- 42.7/376.0 MB 6.9 MB/s eta 0:00:49\n",
      "   ---- ----------------------------------- 45.1/376.0 MB 7.0 MB/s eta 0:00:48\n",
      "   ---- ----------------------------------- 46.7/376.0 MB 7.1 MB/s eta 0:00:47\n",
      "   ----- ---------------------------------- 48.8/376.0 MB 7.1 MB/s eta 0:00:46\n",
      "   ----- ---------------------------------- 51.1/376.0 MB 7.2 MB/s eta 0:00:45\n",
      "   ----- ---------------------------------- 53.2/376.0 MB 7.3 MB/s eta 0:00:45\n",
      "   ----- ---------------------------------- 55.3/376.0 MB 7.4 MB/s eta 0:00:44\n",
      "   ------ --------------------------------- 57.1/376.0 MB 7.4 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 59.0/376.0 MB 7.4 MB/s eta 0:00:43\n",
      "   ------ --------------------------------- 61.1/376.0 MB 7.5 MB/s eta 0:00:42\n",
      "   ------ --------------------------------- 63.7/376.0 MB 7.6 MB/s eta 0:00:41\n",
      "   ------ --------------------------------- 64.7/376.0 MB 7.5 MB/s eta 0:00:42\n",
      "   ------- -------------------------------- 67.6/376.0 MB 7.7 MB/s eta 0:00:41\n",
      "   ------- -------------------------------- 70.3/376.0 MB 7.8 MB/s eta 0:00:40\n",
      "   ------- -------------------------------- 73.1/376.0 MB 7.9 MB/s eta 0:00:39\n",
      "   -------- ------------------------------- 75.5/376.0 MB 8.0 MB/s eta 0:00:38\n",
      "   -------- ------------------------------- 77.1/376.0 MB 8.0 MB/s eta 0:00:38\n",
      "   -------- ------------------------------- 77.6/376.0 MB 7.9 MB/s eta 0:00:38\n",
      "   -------- ------------------------------- 77.6/376.0 MB 7.9 MB/s eta 0:00:38\n",
      "   -------- ------------------------------- 77.9/376.0 MB 7.7 MB/s eta 0:00:39\n",
      "   -------- ------------------------------- 78.1/376.0 MB 7.6 MB/s eta 0:00:40\n",
      "   -------- ------------------------------- 78.4/376.0 MB 7.4 MB/s eta 0:00:41\n",
      "   -------- ------------------------------- 78.6/376.0 MB 7.3 MB/s eta 0:00:41\n",
      "   -------- ------------------------------- 79.2/376.0 MB 7.1 MB/s eta 0:00:42\n",
      "   -------- ------------------------------- 79.7/376.0 MB 7.0 MB/s eta 0:00:43\n",
      "   -------- ------------------------------- 80.2/376.0 MB 6.9 MB/s eta 0:00:43\n",
      "   -------- ------------------------------- 81.0/376.0 MB 6.9 MB/s eta 0:00:43\n",
      "   -------- ------------------------------- 81.5/376.0 MB 6.8 MB/s eta 0:00:44\n",
      "   -------- ------------------------------- 82.6/376.0 MB 6.8 MB/s eta 0:00:44\n",
      "   -------- ------------------------------- 83.4/376.0 MB 6.7 MB/s eta 0:00:44\n",
      "   -------- ------------------------------- 84.1/376.0 MB 6.7 MB/s eta 0:00:44\n",
      "   --------- ------------------------------ 85.5/376.0 MB 6.6 MB/s eta 0:00:44\n",
      "   --------- ------------------------------ 86.5/376.0 MB 6.6 MB/s eta 0:00:44\n",
      "   --------- ------------------------------ 87.8/376.0 MB 6.6 MB/s eta 0:00:44\n",
      "   --------- ------------------------------ 89.1/376.0 MB 6.6 MB/s eta 0:00:44\n",
      "   --------- ------------------------------ 90.4/376.0 MB 6.6 MB/s eta 0:00:44\n",
      "   --------- ------------------------------ 92.0/376.0 MB 6.6 MB/s eta 0:00:44\n",
      "   --------- ------------------------------ 93.6/376.0 MB 6.6 MB/s eta 0:00:43\n",
      "   ---------- ----------------------------- 95.2/376.0 MB 6.6 MB/s eta 0:00:43\n",
      "   ---------- ----------------------------- 96.7/376.0 MB 6.6 MB/s eta 0:00:43\n",
      "   ---------- ----------------------------- 98.3/376.0 MB 6.7 MB/s eta 0:00:42\n",
      "   ---------- ----------------------------- 99.9/376.0 MB 6.6 MB/s eta 0:00:42\n",
      "   ---------- ----------------------------- 101.7/376.0 MB 6.7 MB/s eta 0:00:42\n",
      "   ----------- ---------------------------- 103.8/376.0 MB 6.7 MB/s eta 0:00:41\n",
      "   ----------- ---------------------------- 105.9/376.0 MB 6.8 MB/s eta 0:00:40\n",
      "   ----------- ---------------------------- 108.0/376.0 MB 6.8 MB/s eta 0:00:40\n",
      "   ----------- ---------------------------- 110.4/376.0 MB 6.9 MB/s eta 0:00:39\n",
      "   ----------- ---------------------------- 112.5/376.0 MB 6.9 MB/s eta 0:00:39\n",
      "   ------------ --------------------------- 114.6/376.0 MB 6.9 MB/s eta 0:00:38\n",
      "   ------------ --------------------------- 117.2/376.0 MB 7.0 MB/s eta 0:00:37\n",
      "   ------------ --------------------------- 119.8/376.0 MB 7.1 MB/s eta 0:00:37\n",
      "   ------------- -------------------------- 122.4/376.0 MB 7.1 MB/s eta 0:00:36\n",
      "   ------------- -------------------------- 125.0/376.0 MB 7.2 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 127.9/376.0 MB 7.3 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 130.8/376.0 MB 7.3 MB/s eta 0:00:34\n",
      "   -------------- ------------------------- 133.7/376.0 MB 7.4 MB/s eta 0:00:33\n",
      "   -------------- ------------------------- 136.3/376.0 MB 7.5 MB/s eta 0:00:33\n",
      "   -------------- ------------------------- 139.5/376.0 MB 7.6 MB/s eta 0:00:32\n",
      "   --------------- ------------------------ 142.3/376.0 MB 7.6 MB/s eta 0:00:31\n",
      "   --------------- ------------------------ 145.5/376.0 MB 7.7 MB/s eta 0:00:30\n",
      "   --------------- ------------------------ 148.9/376.0 MB 7.8 MB/s eta 0:00:30\n",
      "   ---------------- ----------------------- 152.3/376.0 MB 7.9 MB/s eta 0:00:29\n",
      "   ---------------- ----------------------- 155.5/376.0 MB 8.0 MB/s eta 0:00:28\n",
      "   ---------------- ----------------------- 158.1/376.0 MB 8.0 MB/s eta 0:00:28\n",
      "   ----------------- ---------------------- 160.7/376.0 MB 8.0 MB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 163.6/376.0 MB 8.1 MB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 165.7/376.0 MB 8.1 MB/s eta 0:00:26\n",
      "   ----------------- ---------------------- 167.5/376.0 MB 8.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 169.9/376.0 MB 8.2 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 171.7/376.0 MB 8.2 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 174.1/376.0 MB 8.2 MB/s eta 0:00:25\n",
      "   ------------------ --------------------- 176.2/376.0 MB 8.2 MB/s eta 0:00:25\n",
      "   ------------------ --------------------- 178.5/376.0 MB 8.2 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 180.9/376.0 MB 8.3 MB/s eta 0:00:24\n",
      "   ------------------- -------------------- 183.0/376.0 MB 8.3 MB/s eta 0:00:24\n",
      "   ------------------- -------------------- 185.9/376.0 MB 8.3 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 188.7/376.0 MB 8.4 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 191.4/376.0 MB 8.4 MB/s eta 0:00:22\n",
      "   -------------------- ------------------- 194.2/376.0 MB 8.5 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 197.4/376.0 MB 8.5 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 200.0/376.0 MB 8.5 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 203.2/376.0 MB 8.6 MB/s eta 0:00:21\n",
      "   --------------------- ------------------ 206.3/376.0 MB 8.7 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 209.7/376.0 MB 8.7 MB/s eta 0:00:20\n",
      "   ---------------------- ----------------- 212.9/376.0 MB 8.8 MB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 216.0/376.0 MB 8.8 MB/s eta 0:00:19\n",
      "   ----------------------- ---------------- 219.2/376.0 MB 8.9 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 221.0/376.0 MB 8.9 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 222.8/376.0 MB 8.9 MB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 224.7/376.0 MB 8.9 MB/s eta 0:00:18\n",
      "   ------------------------ --------------- 226.5/376.0 MB 8.9 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 228.3/376.0 MB 8.9 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 230.4/376.0 MB 8.9 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 232.5/376.0 MB 8.9 MB/s eta 0:00:17\n",
      "   ------------------------ --------------- 234.9/376.0 MB 8.9 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 237.2/376.0 MB 8.9 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 239.6/376.0 MB 8.9 MB/s eta 0:00:16\n",
      "   ------------------------- -------------- 242.0/376.0 MB 8.9 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 244.6/376.0 MB 9.0 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 247.2/376.0 MB 9.0 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 249.8/376.0 MB 9.0 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 252.7/376.0 MB 9.1 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 255.1/376.0 MB 9.1 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 258.2/376.0 MB 9.1 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 261.1/376.0 MB 9.1 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 264.2/376.0 MB 9.1 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 267.4/376.0 MB 9.1 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 270.8/376.0 MB 9.0 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 274.2/376.0 MB 9.1 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 277.6/376.0 MB 9.1 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 280.2/376.0 MB 9.3 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 281.8/376.0 MB 9.5 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 283.1/376.0 MB 9.5 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 284.4/376.0 MB 9.6 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 286.0/376.0 MB 9.6 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 287.3/376.0 MB 9.6 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 288.9/376.0 MB 9.6 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 290.7/376.0 MB 9.7 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 292.6/376.0 MB 9.7 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 294.1/376.0 MB 9.7 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 296.2/376.0 MB 9.8 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 298.3/376.0 MB 9.8 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 300.4/376.0 MB 9.8 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 302.5/376.0 MB 9.8 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 304.6/376.0 MB 9.8 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 307.0/376.0 MB 9.8 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 309.6/376.0 MB 9.9 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 312.0/376.0 MB 9.9 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 314.6/376.0 MB 9.9 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 316.9/376.0 MB 9.9 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 319.8/376.0 MB 9.9 MB/s eta 0:00:06\n",
      "   --------------------------------- ----- 322.7/376.0 MB 10.0 MB/s eta 0:00:06\n",
      "   --------------------------------- ----- 325.8/376.0 MB 10.0 MB/s eta 0:00:06\n",
      "   ---------------------------------- ---- 328.7/376.0 MB 10.1 MB/s eta 0:00:05\n",
      "   ---------------------------------- ---- 331.6/376.0 MB 10.1 MB/s eta 0:00:05\n",
      "   ---------------------------------- ---- 334.5/376.0 MB 10.1 MB/s eta 0:00:05\n",
      "   ----------------------------------- --- 337.9/376.0 MB 10.1 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 341.0/376.0 MB 10.7 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 344.2/376.0 MB 11.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 347.1/376.0 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 349.7/376.0 MB 11.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 352.3/376.0 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 354.7/376.0 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 357.3/376.0 MB 11.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 360.2/376.0 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 363.1/376.0 MB 11.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 365.4/376.0 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  367.5/376.0 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  369.6/376.0 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  372.0/376.0 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  374.1/376.0 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 376.0/376.0 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 2.6/4.3 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.2/4.3 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 9.2 MB/s eta 0:00:00\n",
      "Downloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 11.6 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.6/26.4 MB 7.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 4.2/26.4 MB 10.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 6.3/26.4 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.4/26.4 MB 10.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 10.7/26.4 MB 10.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 13.1/26.4 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 16.0/26.4 MB 10.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.8/26.4 MB 10.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.7/26.4 MB 10.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.5/26.4 MB 10.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.1/26.4 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 2.6/5.5 MB 13.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 14.0 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.1-cp312-cp312-win_amd64.whl (306 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 keras-3.9.2 libclang-18.1.1 ml-dtypes-0.5.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install webrtcvad-wheels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sounddevice numpy whispercpp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing local transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "# Load processor and model\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny.en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whispercpp import Whisper\n",
    "whisper_model = Whisper.from_pretrained(\"base.en\")  # Note method change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Whisper model (tiny.en for low latency)\n",
    "whisper_model = Whisper(\"tiny.en\")  # Replace with \"base.en\" or larger models if needed\n",
    "\n",
    "# Configuration\n",
    "SAMPLERATE = 16000  # Whisper works best at this rate\n",
    "BLOCKSIZE = 1024    # 64ms chunks (tweak for lower latency)\n",
    "DEVICE_ID = 1      # Replace with your virtual cable device index (use sd.query_devices())\n",
    "audio_queue = queue.Queue(maxsize=10)  # Thread-safe buffer for audio chunks\n",
    "\n",
    "# Callback function to capture audio chunks\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"Non-blocking audio chunk handler.\"\"\"\n",
    "    if status:\n",
    "        print(f\"Audio callback error: {status}\")\n",
    "    audio_queue.put(indata[:, 0].copy())  # Convert to mono and add to queue\n",
    "\n",
    "# Process audio chunks in real-time using Whisper\n",
    "def process_audio():\n",
    "    \"\"\"Continuously process audio chunks from the queue.\"\"\"\n",
    "    print(\"Starting transcription...\")\n",
    "    while True:\n",
    "        try:\n",
    "            # Get an audio chunk from the queue\n",
    "            chunk = audio_queue.get()\n",
    "            # Transcribe the chunk using Whisper.cpp\n",
    "            text = whisper_model.transcribe(chunk.astype(np.float32))\n",
    "            if text.strip():  # If transcription is not empty\n",
    "                print(f\"Transcribed Text: {text}\")\n",
    "                # Example: Trigger response for specific keywords\n",
    "                if \"memoization\" in text.lower():\n",
    "                    print(\"[Response] Memoization is an optimization technique...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during transcription: {e}\")\n",
    "\n",
    "# Start the real-time audio stream and transcription loop\n",
    "def start_real_time_transcription():\n",
    "    \"\"\"Start the audio stream and transcription.\"\"\"\n",
    "    try:\n",
    "        print(\"Initializing audio stream...\")\n",
    "        with sd.InputStream(samplerate=SAMPLERATE, blocksize=BLOCKSIZE,\n",
    "                            device=DEVICE_ID, channels=1, callback=audio_callback):\n",
    "            process_audio()  # Start processing audio chunks in real-time\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing audio stream: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting real-time meeting assistant...\")\n",
    "    start_real_time_transcription()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing online API transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_completion = client.chat.completions.create(\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"system\",\n",
    "#             \"content\": \"you are a helpful assistant.\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": \"Explain the importance of fast language models\",\n",
    "#         }\n",
    "#     ],\n",
    "#     model=\"llama-3.3-70b-versatile\",\n",
    "# )\n",
    "\n",
    "# print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio recording parameters\n",
    "CHUNK = 480\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "VAD_AGGRESSIVENESS = 3  # 1-3 (3=most aggressive noise filtering)\n",
    "MIN_SPEECH_DURATION = 1.2  # Seconds of speech to trigger processing\n",
    "PRE_SPEECH_BUFFER = 2.0  # Seconds to capture before speech starts\n",
    "POST_SPEECH_BUFFER = 1.5  # Seconds to capture after speech ends\n",
    "MAX_BUFFER_SECONDS = 5 # Maximum buffer size in seconds\n",
    "\n",
    "vad = webrtcvad.Vad(VAD_AGGRESSIVENESS)  # Aggressive noise filtering\n",
    "audio_queue = queue.Queue()\n",
    "processing_lock = threading.Lock()\n",
    "in_speech = False\n",
    "speech_start = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_lock = threading.Lock()\n",
    "audio_buffer = np.array([], dtype=np.int16)  # Declare and initialize audio_buffer globally\n",
    "in_speech = False\n",
    "speech_start = 0\n",
    "buffer_start_idx = 0\n",
    "\n",
    "def record_audio():\n",
    "    \"\"\"VAD based audio recording with threading.\"\"\"\n",
    "    global audio_buffer, in_speech, speech_start, buffer_start_idx\n",
    "    \n",
    "    def callback(in_data, frame_count, time_info, status):\n",
    "        global audio_buffer, in_speech, speech_start, buffer_start_idx\n",
    "        \n",
    "        pcm = np.frombuffer(in_data, dtype=np.int16)\n",
    "\n",
    "        with processing_lock:\n",
    "            is_speech = vad.is_speech(pcm.tobytes(), RATE, len(pcm))\n",
    "            \n",
    "            if is_speech:\n",
    "                if not in_speech:\n",
    "                    # Speech start: track buffer position\n",
    "                    speech_start = time.time()\n",
    "                    buffer_start_idx = max(0, len(audio_buffer) - RATE//2)  # 0.5s lookback\n",
    "                    in_speech = True\n",
    "                audio_buffer = np.concatenate([audio_buffer, pcm])\n",
    "            else:\n",
    "                if in_speech:\n",
    "                    # Speech end: calculate captured duration\n",
    "                    captured_seconds = (len(audio_buffer) - buffer_start_idx) / RATE\n",
    "                    if captured_seconds >= MIN_SPEECH_DURATION:\n",
    "                        # Capture pre/post speech context\n",
    "                        pre_samples = min(buffer_start_idx, int(RATE * PRE_SPEECH_BUFFER))\n",
    "                        post_samples = int(RATE * POST_SPEECH_BUFFER)\n",
    "                        \n",
    "                        segment = audio_buffer[\n",
    "                            buffer_start_idx - pre_samples : \n",
    "                            len(audio_buffer) + post_samples\n",
    "                        ]\n",
    "                        audio_queue.put(segment.copy())\n",
    "                        \n",
    "                    in_speech = False\n",
    "\n",
    "        print(f\"VAD: {'üó£Ô∏è' if is_speech else 'üîá'} | Buffer: {len(audio_buffer)/RATE:.1f}s\", end='\\r')\n",
    "        return (None, pyaudio.paContinue)\n",
    "\n",
    "    vad = webrtcvad.Vad(VAD_AGGRESSIVENESS)\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE,\n",
    "                    input=True, frames_per_buffer=CHUNK,\n",
    "                    stream_callback=callback, start=False)\n",
    "    stream.start_stream()\n",
    "    return stream\n",
    "\n",
    "def save_audio(audio_numpy):\n",
    "    \"\"\"Save numpy array directly\"\"\"\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as f:\n",
    "        sf.write(f, audio_numpy, RATE, format='WAV', subtype='PCM_16')\n",
    "        return f.name\n",
    "\n",
    "def transcribe_audio(audio_numpy):\n",
    "    \"\"\"Direct memory-based transcription\"\"\"\n",
    "    # Convert numpy array to bytes buffer\n",
    "    buffer = BytesIO()\n",
    "    audio_numpy = audio_numpy.astype(np.float32) / 32768.0 # Normalize to float32\n",
    "    sf.write(buffer, audio_numpy, RATE, format='WAV', \n",
    "             subtype='FLOAT')\n",
    "    buffer.seek(0)\n",
    "\n",
    "    try:\n",
    "        response = client.audio.transcriptions.create(\n",
    "            file=(\"audio.wav\", buffer.read()),\n",
    "            model=\"whisper-large-v3-turbo\",  # Verified correct model name\n",
    "            response_format=\"text\",\n",
    "            language=\"en\",\n",
    "            temperature=0.2,\n",
    "        )\n",
    "        return response.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Transcription failed: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def play_audio(filename=\"recorded_audio.wav\"):\n",
    "    import pyaudio\n",
    "    import wave\n",
    "\n",
    "    wf = wave.open(filename, 'rb')\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Open stream for playback\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=wf.getframerate(),\n",
    "                    output=True)\n",
    "\n",
    "    # Read and play back data in chunks\n",
    "    chunk = 1024\n",
    "    data = wf.readframes(chunk)\n",
    "    while data:\n",
    "        stream.write(data)\n",
    "        data = wf.readframes(chunk)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    print(\"Playback finished.\")\n",
    "\n",
    "def process_transcription(text):\n",
    "    \"\"\"Process the transcribed text and generate a response.\"\"\"\n",
    "    cleaned = text.lower().strip()[:200] # Limit input length\n",
    "    if not cleaned:\n",
    "        return \"No speech detected\"\n",
    "    keywords = {\n",
    "        \"memoization\": \"Memoization is an optimization technique that stores results of expensive function calls.\",\n",
    "        \"recursion\": \"Recursion is a method where a function calls itself to solve smaller instances of a problem.\",\n",
    "        \"dynamic programming\": \"Dynamic programming is a method for solving complex problems by breaking them down into simpler subproblems.\",\n",
    "        \"algorithm\": \"An algorithm is a step-by-step procedure for calculations.\",\n",
    "        \"data structure\": \"A data structure is a particular way of organizing and storing data in a computer.\",\n",
    "        \"machine learning\": \"Machine learning is a subset of AI that enables systems to learn from data.\",\n",
    "        \"artificial intelligence\": \"Artificial intelligence is the simulation of human intelligence in machines.\",\n",
    "        \"deep learning\": \"Deep learning is a subset of machine learning that uses neural networks with many layers.\",\n",
    "        \"natural language processing\": \"Natural language processing is a field of AI that focuses on the interaction between computers and humans through natural language.\",\n",
    "        \"computer vision\": \"Computer vision is a field of AI that enables computers to interpret and understand visual information from the world.\",\n",
    "        \"reinforcement learning\": \"Reinforcement learning is a type of machine learning where an agent learns to make decisions by taking actions in an environment to maximize cumulative reward.\",\n",
    "        \"supervised learning\": \"Supervised learning is a type of machine learning where the model is trained on labeled data.\",\n",
    "        \"unsupervised learning\": \"Unsupervised learning is a type of machine learning where the model is trained on unlabeled data.\",\n",
    "        \"transfer learning\": \"Transfer learning is a technique where a model developed for one task is reused as the starting point for a model on a second task.\",\n",
    "        \"chini\": \"Chini to pagal hai.\"\n",
    "    }\n",
    "    \n",
    "    for kw in sorted(keywords.keys(), key=len, reverse=True):\n",
    "        if kw in cleaned:\n",
    "            return keywords[kw]\n",
    "    return f\"Command not recognized: {cleaned[:30]}...\"\n",
    "\n",
    "def copy_to_clipboard(text):\n",
    "    \"\"\"Copy text to clipboard.\"\"\"\n",
    "    pyperclip.copy(text)\n",
    "    print(\"Response copied to clipboard!\")\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     while True:\n",
    "#         input(\"Press Enter to start recording...\")\n",
    "#         audio_frames = record_audio()\n",
    "#         temp_file_path = save_audio(audio_frames)\n",
    "#         transcription = transcribe_audio(temp_file_path)\n",
    "#         print(\"Transcription:\", transcription)\n",
    "#         os.remove(temp_file_path)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, logging\n",
    "logging.set_verbosity_error()  # Suppress warnings\n",
    "\n",
    "class QuestionDetector:\n",
    "    def __init__(self):\n",
    "        # Lightweight model for real-time use (90MB)\n",
    "        self.classifier = pipeline(\n",
    "            \"text-classification\", \n",
    "            model=\"shahrukhx01/question-vs-statement-classifier\"\n",
    "        )\n",
    "\n",
    "        self.client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "        self.model = \"llama3-70b-8192\"\n",
    "        \n",
    "    def detect_question(self, text):\n",
    "        \"\"\"Returns True if input text is a question\"\"\"\n",
    "        if not text.strip():\n",
    "            return False\n",
    "            \n",
    "        result = self.classifier(text[:512])  # Trim to model's max length\n",
    "        return result[0]['label'] == 'LABEL_1' and result[0]['score'] > 0.85\n",
    "    \n",
    "    def generate_answer(self, question, context=\"\"):\n",
    "        \"\"\"Generate an answer to the question using Groq API\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                messages=[{\"role\": \"system\", \"content\": f\"\"\"You are an expert interview coach. Generate concise, professional responses using:\n",
    "                        - STAR method (Situation, Task, Action, Result)\n",
    "                        - Max 3 sentences\n",
    "                        - Incorporate keywords: {context}\n",
    "                        - Maintain a professional tone\"\"\"},\n",
    "                          {\"role\": \"user\", \"content\": f\"Suggest response to: {question}\"}],\n",
    "                model=self.model,\n",
    "                temperature=0.2,\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating answer: {e}\")\n",
    "            return \"Sorry, I couldn't generate an answer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: What is your greatest strength?\n",
      "Detected as a question.\n",
      "Generated Answer: Here's a possible response:\n",
      "\n",
      "\"My greatest strength is my ability to lead cross-functional teams in delivering scalable and efficient solutions, leveraging my technical expertise in AWS and Python. In my previous role, I successfully led a team of engineers in developing a cloud-based application using React, resulting in a 30% increase in deployment speed and a 25% reduction in costs. This experience has taught me the importance of effective team leadership, and I'm confident in my ability to drive similar results in this role.\"\n",
      "\n",
      "Text: Tell me about a time you solved a problem.\n",
      "Detected as a statement.\n",
      "Text: I worked at XYZ Corp for 5 years.\n",
      "Detected as a statement.\n",
      "Text: Why did you leave your previous job?\n",
      "Detected as a question.\n",
      "Generated Answer: Here's a possible response:\n",
      "\n",
      "\"I left my previous role as a Senior Software Engineer at XYZ Corporation due to a desire to expand my technical skills in cloud computing, specifically with AWS, and to take on more leadership responsibilities. In my previous position, I had successfully led a team in developing a React-based application, but I felt limited in my ability to drive technical strategy and innovation. I'm excited to leverage my Python expertise and team leadership skills in a new role that offers more opportunities for growth and impact.\"\n",
      "\n",
      "Text: It was great working with my team.\n",
      "Detected as a statement.\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"What is your greatest strength?\", \n",
    "    \"Tell me about a time you solved a problem.\",\n",
    "    \"I worked at XYZ Corp for 5 years.\",\n",
    "    \"Why did you leave your previous job?\",\n",
    "    \"It was great working with my team.\"\n",
    "]\n",
    "context = \"AWS, Python, React, Team Leadership\"\n",
    "\n",
    "qd = QuestionDetector()\n",
    "for text in texts:\n",
    "    print(f\"Text: {text}\")\n",
    "    if qd.detect_question(text):\n",
    "        print(\"Detected as a question.\")\n",
    "        response = qd.generate_answer(text, context)\n",
    "        print(f\"Generated Answer: {response}\\n\")\n",
    "    else:\n",
    "        print(\"Detected as a statement.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé§ Listening... (Press Ctrl+C to stop)\n",
      "VAD: üîá | Buffer: 1.9ss\n",
      "üìù Heard: Hi, how are you?\n",
      "VAD: üîá | Buffer: 4.2ss\n",
      "üìù Heard: Hi, how are you? So what is up?\n",
      "VAD: üó£Ô∏è | Buffer: 8.2s\n",
      "üìù Heard: so what is up? also from denoiser import enhance\n",
      "VAD: üîá | Buffer: 10.2ss\n",
      "üìù Heard: Also from denoiser import enhance another tool to add on top of it to remove noise.\n",
      "VAD: üîá | Buffer: 14.2ss\n",
      "üìù Heard: on top of it to remove noise. Basically you can remove noise using this tool\n",
      "VAD: üó£Ô∏è | Buffer: 15.3s\n",
      "üìù Heard: remove noise using these toolkits and you know\n",
      "VAD: üîá | Buffer: 16.5ss\n",
      "üõë Stopping...\n",
      "\n",
      "=== COMPLETE TRANSCRIPT ===\n",
      "1. Hi, how are you?\n",
      "2. Hi, how are you? So what is up?\n",
      "3. so what is up? also from denoiser import enhance\n",
      "4. Also from denoiser import enhance another tool to add on top of it to remove noise.\n",
      "5. on top of it to remove noise. Basically you can remove noise using this tool\n",
      "6. remove noise using these toolkits and you know\n"
     ]
    }
   ],
   "source": [
    "FULL_TRANSCRIPT = []  # Simple list to store all spoken phrases\n",
    "LAST_RESPONSE = \"\"\n",
    "\n",
    "def main():\n",
    "    global FULL_TRANSCRIPT, LAST_RESPONSE\n",
    "\n",
    "    # Initialize detector\n",
    "    qd = QuestionDetector()\n",
    "    \n",
    "    stream = record_audio()\n",
    "    print(\"üé§ Listening... (Press Ctrl+C to stop)\")\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            try:\n",
    "                audio_data = audio_queue.get(timeout=0.2)\n",
    "                \n",
    "                if audio_data.size >= int(RATE * 0.3):  # Minimal audio threshold\n",
    "                    # Core pipeline\n",
    "                    transcription = transcribe_audio(audio_data)\n",
    "                    # response = process_transcription(transcription)\n",
    "\n",
    "                    # if question detected\n",
    "                    if qd.detect_question(transcription):\n",
    "                        response = client.chat.completions.create(\n",
    "                            messages=[\n",
    "                                {\n",
    "                                    \"role\": \"user\",\n",
    "                                    \"content\": transcription,\n",
    "                                }\n",
    "                            ],\n",
    "                            model=\"llama-3.3-70b-versatile\",\n",
    "                        ).choices[0].message.content\n",
    "                        print(f\"üí¨ Response: {response}\")\n",
    "                    \n",
    "                    # Simple storage\n",
    "                    FULL_TRANSCRIPT.append(transcription)\n",
    "                    # LAST_RESPONSE = response\n",
    "                    \n",
    "                    # Immediate feedback\n",
    "                    print(f\"\\nüìù Heard: {transcription}\")\n",
    "                    # print(f\"üí¨ Response: {response}\")\n",
    "                    # pyperclip.copy(response)\n",
    "                    \n",
    "            except queue.Empty:\n",
    "                continue\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nüõë Stopping...\")\n",
    "        \n",
    "    finally:\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        \n",
    "        # Simple verification\n",
    "        print(\"\\n=== COMPLETE TRANSCRIPT ===\")\n",
    "        for i, phrase in enumerate(FULL_TRANSCRIPT, 1):\n",
    "            print(f\"{i}. {phrase}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
